[package]
name = "finch"
version = "0.7.17"
edition = "2021"
authors = ["Darwin Finch Contributors"]
description = "AI that evolves with your code - distributed assistant with hierarchical memory"
license = "LicenseRef-PolyForm-Noncommercial-1.0"
repository = "https://github.com/darwin-finch/finch"

[dependencies]
# CLI
clap = { version = "4.4", features = ["derive"] }
crossterm = "0.28"
ctrlc = "3.4"
rustyline = "13.0"

# TUI (Phase 2: Terminal UI refactor)
ratatui = "0.28"
ansi-to-tui = "6.0"
tui-textarea = "0.6"  # Text area widget for ratatui (TUI mode)

# Async runtime
tokio = { version = "1.35", features = ["full"] }
tokio-util = "0.7"
futures = "0.3"

# Global state for TUI output system (Phase 3.5)
once_cell = "1.19"

# HTTP client for Claude API
reqwest = { version = "0.11", default-features = false, features = ["json", "stream", "rustls-tls"] }

# HTTP server
axum = "0.7"
tower = "0.4"
tower-http = { version = "0.5", features = ["trace", "cors"] }

# Service discovery (Phase 3: Daemon-Only Mode)
mdns-sd = "0.11"  # Cross-platform mDNS/DNS-SD for service advertisement
hostname = "0.4"  # System hostname detection

# Memory system (Phase 4: Hierarchical Memory)
rusqlite = { version = "0.32", features = ["bundled"] }  # SQLite with bundled library

# Session management
dashmap = "5.5"

# Metrics
prometheus = "0.14"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Configuration
config = "0.14"
dirs = "5.0"
toml = "0.8"

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Clipboard access (for image paste support)
arboard = { version = "3.6", features = ["image-data"] }

# Base64 encoding (for image data and license key encoding)
base64 = "0.22"

# Ed25519 signature verification for offline license key validation
ed25519-dalek = { version = "2", features = ["serde", "rand_core"] }

# PNG encoding (for clipboard image data → PNG bytes)
png = "0.17"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "fmt"] }
tracing-log = "0.2"  # Bridge log crate → tracing (Phase 3.5)

# Time and hashing
chrono = { version = "0.4", features = ["serde"] }
sha2 = "0.10"
uuid = { version = "1.0", features = ["v4", "v5", "serde"] }

# Text processing for TF-IDF
rust-stemmers = "1.2"

# Machine Learning (Dual providers: ONNX Runtime + Candle)
# ONNX Runtime (recommended for most users)
ort = { version = "2.0.0-rc.11", features = ["download-binaries", "ndarray"] }
ndarray = "0.17"  # Multi-dimensional arrays for ONNX tensor creation
# Candle (alternative provider, optional)
candle-core = { version = "0.8", optional = true }
candle-nn = { version = "0.8", optional = true }
candle-transformers = { version = "0.8", optional = true }
# Shared dependencies
sysinfo = "0.32"  # System RAM detection for model selection
tokenizers = "0.21"  # Tokenization (used by both ONNX and Candle)
hf-hub = { version = "0.4", default-features = false, features = ["tokio", "ureq", "rustls-tls"] }  # HuggingFace Hub integration
indicatif = "0.17"  # Progress bars for download tracking
rand = "0.8"  # Random number generation for sampling
safetensors = "0.4"  # Model weight loading (used by Candle)

# For web tools (Phase 3)
scraper = "0.18"

# MCP (Model Context Protocol) for external tool integration (Phase 4)
rust-mcp-sdk = { version = "0.8", default-features = false, features = ["client", "stdio", "sse"] }

# Tools
async-trait = "0.1"
regex = "1.10"
glob = "0.3"
walkdir = "2.4"
fs2 = "0.4"  # File locking for concurrent weight updates

# CoreML/Metal support (macOS only)
[target.'cfg(target_os = "macos")'.dependencies]
# ONNX Runtime uses CoreML execution provider
# Candle uses Metal (requires candle feature flag)
candle-metal-kernels = { version = "0.8", optional = true }
# GUI automation (Phase 3: Accessibility tools)
core-graphics = "0.23"  # Mouse/keyboard events for GUI automation
core-foundation = "0.10"  # Foundation types (required by core-graphics)

# Unix signal handling (for daemon process checks)
[target.'cfg(unix)'.dependencies]
nix = { version = "0.29", features = ["signal"] }

[dev-dependencies]
mockito = "1.2"
tempfile = "3.8"
tower = { version = "0.5", features = ["util"] }  # ServiceExt::oneshot() for integration tests
http-body-util = "0.1"  # axum::body::to_bytes helper
tokio = { version = "1.35", features = ["test-util"] }  # start_paused for time-controlled tests

[features]
default = ["onnx", "candle"]  # ONNX Runtime + Candle are the default providers
onnx = []  # ONNX Runtime support (always available)
candle = ["dep:candle-core", "dep:candle-nn", "dep:candle-transformers"]  # Candle support (optional)
candle-metal = ["candle", "dep:candle-metal-kernels"]  # Candle with Metal acceleration (macOS only)
cuda = []  # CUDA support (requires CUDA toolkit)
all-providers = ["onnx", "candle"]  # Both inference providers

[[bin]]
name = "finch"
path = "src/main.rs"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
